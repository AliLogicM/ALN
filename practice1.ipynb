{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1665e195",
   "metadata": {},
   "source": [
    "# Utilizando la columna “opinión” del set de datos de opiniones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da2e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Cargar el archivo Excel\n",
    "file_path = 'corpus/Rest_Mex_2022_Sentiment_Analysis_Track_Train.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6ed45",
   "metadata": {},
   "source": [
    "- Normalizar el texto usando spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ab06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import unidecode\n",
    "\n",
    "# Cargar el modelo en español de spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Función para normalizar el texto usando spaCy\n",
    "def normalize_text(text):\n",
    "    # Cast a str\n",
    "    text = str(text)\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Quitar acentos\n",
    "    text = unidecode.unidecode(text)\n",
    "    # Procesar el texto con spaCy\n",
    "    doc = nlp(text)\n",
    "    # Eliminar stop words y puntuación, y realizar lematización\n",
    "    text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfeef15",
   "metadata": {},
   "source": [
    "- Normalzar las opiniones paralelizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ae983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def parallel_processing_threads(data, func):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(func, data))\n",
    "    return results\n",
    "\n",
    "# Normaliza el dataframe en paralelo\n",
    "df['Normalized_Opinion'] = parallel_processing_threads(df['Opinion'], normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90e97a",
   "metadata": {},
   "source": [
    "- Entrenar un modelo Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f163a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Preparar los datos\n",
    "tokenized_opinions = [opinion.split() for opinion in df['Normalized_Opinion'].astype(str)]\n",
    "tagged_data = [TaggedDocument(words=words, tags=[str(attraction)]) for words, attraction in zip(tokenized_opinions, df['Attraction'].astype(str))] # Se puede hacer para polarity\n",
    "\n",
    "# Construir y entrenar el modelo\n",
    "model = Doc2Vec(vector_size=50, window=5, min_count=1, workers=4, epochs=20)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Guardar el modelo para uso futuro\n",
    "model.save(\"doc2vec_model_knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec80fd1",
   "metadata": {},
   "source": [
    "- Entrenar un algoritmo knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575817bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc2vec_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ali\\Documents\\ESCOM\\8BM1\\ALN\\Code\\ALN\\practice1.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ali/Documents/ESCOM/8BM1/ALN/Code/ALN/practice1.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ali/Documents/ESCOM/8BM1/ALN/Code/ALN/practice1.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Cargar el modelo Doc2Vec entrenado\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ali/Documents/ESCOM/8BM1/ALN/Code/ALN/practice1.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m Doc2Vec\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mdoc2vec_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ali/Documents/ESCOM/8BM1/ALN/Code/ALN/practice1.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Preparar los datos para el entrenamiento\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ali/Documents/ESCOM/8BM1/ALN/Code/ALN/practice1.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mNormalized_Opinion\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mNormalized_Opinion\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x) \u001b[39mif\u001b[39;00m pd\u001b[39m.\u001b[39mnotnull(x) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\anaconda3\\envs\\myenv\\Lib\\site-packages\\gensim\\models\\doc2vec.py:809\u001b[0m, in \u001b[0;36mDoc2Vec.load\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a previously saved :class:`~gensim.models.doc2vec.Doc2Vec` model.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \n\u001b[0;32m    788\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \n\u001b[0;32m    807\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Doc2Vec, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39mload(\u001b[39m*\u001b[39margs, rethrow\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    810\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m ae:\n\u001b[0;32m    811\u001b[0m     logger\u001b[39m.\u001b[39merror(\n\u001b[0;32m    812\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel load error. Was model saved using code from an older Gensim version? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTry loading older model using gensim-3.8.3, then re-saving, to restore \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    814\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcompatibility with current code.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\anaconda3\\envs\\myenv\\Lib\\site-packages\\gensim\\models\\word2vec.py:1953\u001b[0m, in \u001b[0;36mWord2Vec.load\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mSee Also\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1950\u001b[0m \n\u001b[0;32m   1951\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1952\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1953\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(Word2Vec, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39mload(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1954\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, Word2Vec):\n\u001b[0;32m   1955\u001b[0m         rethrow \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\anaconda3\\envs\\myenv\\Lib\\site-packages\\gensim\\utils.py:486\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    482\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m object from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, fname)\n\u001b[0;32m    484\u001b[0m compress, subname \u001b[39m=\u001b[39m SaveLoad\u001b[39m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m--> 486\u001b[0m obj \u001b[39m=\u001b[39m unpickle(fname)\n\u001b[0;32m    487\u001b[0m obj\u001b[39m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m    488\u001b[0m obj\u001b[39m.\u001b[39madd_lifecycle_event(\u001b[39m\"\u001b[39m\u001b[39mloaded\u001b[39m\u001b[39m\"\u001b[39m, fname\u001b[39m=\u001b[39mfname)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\anaconda3\\envs\\myenv\\Lib\\site-packages\\gensim\\utils.py:1460\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munpickle\u001b[39m(fname):\n\u001b[0;32m   1447\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \n\u001b[0;32m   1449\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \n\u001b[0;32m   1459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1460\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m   1461\u001b[0m         \u001b[39mreturn\u001b[39;00m _pickle\u001b[39m.\u001b[39mload(f, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\anaconda3\\envs\\myenv\\Lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 177\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[0;32m    178\u001b[0m     uri,\n\u001b[0;32m    179\u001b[0m     mode,\n\u001b[0;32m    180\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m    181\u001b[0m     buffering\u001b[39m=\u001b[39mbuffering,\n\u001b[0;32m    182\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m    183\u001b[0m     errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    184\u001b[0m     newline\u001b[39m=\u001b[39mnewline,\n\u001b[0;32m    185\u001b[0m )\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32mc:\\Users\\Ali\\anaconda3\\envs\\myenv\\Lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m    361\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39mbuffering, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc2vec_model'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Doc2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo Doc2Vec entrenado\n",
    "model = Doc2Vec.load(\"doc2vec_model\")\n",
    "\n",
    "# Preparar los datos para el entrenamiento\n",
    "df['Normalized_Opinion'] = df['Normalized_Opinion'].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
    "feature_vectors = [model.infer_vector(opinion.split()) for opinion in df['Normalized_Opinion']]\n",
    "X = np.array(feature_vectors)\n",
    "y = df['Attraction'].values\n",
    "\n",
    "# Entrenar el clasificador k-NN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216caa2",
   "metadata": {},
   "source": [
    "- Realizar pruebas con 50 opiniones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ebd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar pruebas con 50 opiniones\n",
    "X_test_sample = X_test[:50]\n",
    "y_test_sample = y_test[:50]\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = knn.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12733f9",
   "metadata": {},
   "source": [
    "- Obtener matriz de confusion y acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98481e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 4  0  1]\n",
      " [ 3 24  2]\n",
      " [ 0  3 13]]\n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Generar la Matriz de Confusión y calcular Accuracy\n",
    "conf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "accuracy = accuracy_score(y_test_sample, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b9c56",
   "metadata": {},
   "source": [
    "- Matriz de confusion para el total del conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b91bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 873   56   90]\n",
      " [ 239 2746  312]\n",
      " [ 298  347 1082]]\n",
      "Accuracy: 0.7779248717524408\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de prueba (80% entrenamiento, 20% prueba)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo: generar la Matriz de Confusión y calcular el Accuracy\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
